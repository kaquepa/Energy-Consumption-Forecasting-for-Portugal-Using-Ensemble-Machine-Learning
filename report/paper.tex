\documentclass[journal]{IEEEtran}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{caption}
\usepackage{url}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[style=ieee]{biblatex}
\usepackage{float}
\usepackage{subcaption}

\addbibresource{references.bib}

\begin{document}

\title{Energy Consumption Forecasting for Portugal Using Ensemble Machine Learning}

\author{Domingos Kaquepa Luciano Graciano\\
\small Department of Electronics, Telecommunications and Informatics\\
\small University of Aveiro, Portugal\\
\small Specialization Program in Machine Learning and Data Analysis\\
\small Email: dkgraciano92@ua.pt\\}

\maketitle

\begin{abstract}
This paper presents a machine learning system for daily energy consumption forecasting in Portugal, achieving a Mean Absolute Percentage Error (MAPE) of 2.45\% for next day predictions. We employed a competition based ensemble approach, comparing RandomForest, LightGBM, and XGBoost algorithms across 7 forecast horizons. The system integrates 15+ years of historical consumption data from Portugal's national grid operator (REN) and historical weather data (Open-Meteo API). We implemented advanced feature engineering including Portuguese specific holiday detection and weather interaction features. Using direct multi-horizon forecasting with 5-fold cross-validation, our best model (LightGBM for horizon +1) achieves $R^2 = 0.891$, outperforming published baselines by 52\%. The complete system is deployed as a production REST API with automated daily updates, demonstrating the effectiveness of domain specific feature engineering combined with gradient boosting methods for energy forecasting.
\end{abstract}

\begin{IEEEkeywords}
Energy forecasting, Time series prediction, Ensemble learning, LightGBM, XGBoost, Feature engineering, Portugal.
\end{IEEEkeywords}

\section{Introduction}

\subsection{Motivation}
Accurate short term energy consumption forecasting is critical for grid operators, energy markets, and policy makers. Portugal's unique energy landscape combining high renewable penetration (wind, solar, hydro) with conventional sources requires precise demand forecasts to ensure grid stability and optimize generation scheduling. The European day ahead electricity market mandates forecasts 12-36 hours in advance, making next day prediction accuracy essential for operational and economic efficiency.

\subsection{Problem Statement}

\textbf{ML Problem Type:} Regression (multi output)

\textbf{Inputs:} 30 features including historical consumption lags, rolling statistics, weather variables, temporal features, and calendar effects (weekends, Portuguese national holidays, bridge days).

\textbf{Outputs:} 7 daily consumption values (GWh) for days $t+1$ through $t+7$

\textbf{Complexity:} 5849 samples $\times$ 30 features, non-linear relationships, seasonal patterns, holiday effects, weather dependencies.

\subsection{Objectives}
\begin{enumerate}
    \item Achieve MAPE < 5\% for next day forecasts (industry best practice)
    \item Develop multi horizon forecasting system (1-7 days ahead)
    \item Compare performance of ensemble methods (RF, LightGBM, XGBoost)
    \item Deploy production ready system with automated pipeline
\end{enumerate}

\subsection{Contributions}

This work presents the first comprehensive, production ready energy forecasting system for Portugal with: 
\begin{itemize}
    \item Long term dataset (15 years vs 2-5 typical);
    \item Portuguese specific calendar features (holidays + bridge days);
    \item Weather interaction features capturing compound effects;
    \item Modern ensemble competition per horizon;
    \item Complete automated pipeline with REST API;
    \item Rigorous validation achieving top tier performance (MAPE 2.45\%).
\end{itemize}

\section{Related Work}

\subsection{Energy Forecasting Literature}

Table~\ref{tab:literature} summarizes key works in short-term electricity forecasting.

\begin{table}[H]
\caption{Comparative Summary of Related Work}
\label{tab:literature}
\centering
\footnotesize
\begin{tabular}{lllcc}
\toprule
Study & Geography & Dataset & MAPE & Method \\
\midrule
Hong et al.~\cite{hong2016} & USA & 4 years & 3.8\% & GBM \\
Haben et al.~\cite{haben2016} & UK & 2 years & 4.2\% & ANN \\
Amarasinghe et al.~\cite{amarasinghe2017} & Australia & 3 years & 5.1\% & LSTM \\
Lago et al.~\cite{lago2018} & Belgium & 3 years & 3.9\% & DNN+ARIMA \\
\textbf{This Work} & \textbf{Portugal} & \textbf{15 years} & \textbf{2.45\%} & \textbf{LightGBM} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Findings from Literature:}

\textit{GEFCom 2014~\cite{hong2016}:} Direct forecasting with independent models per horizon outperformed recursive approaches (80\% of top teams). GBM based methods achieved MAPE 2.5-4.5\%. Feature engineering proved more impactful than algorithm choice.

\textit{UK Smart Meters~\cite{haben2016}:} Feature importance distribution (lags 40\%, weather 25\%, calendar 15\%) validated by ANNs achieving MAPE 4.2\%. Customer segmentation improved accuracy.

\textit{Deep Learning Studies~\cite{amarasinghe2017}:} LSTM achieved MAPE 5.1\% but required large datasets, long training times (4 hours GPU), and lacked interpretability. Tree based methods superior for tabular data <10K samples~\cite{shwartz2022}.

\textit{Hybrid Approaches~\cite{lago2018}:} DNN+ARIMA achieved MAPE 3.9\% but increased complexity. XGBoost standalone competitive (4.1\%).

\textit{Meta-Analysis~\cite{weron2014}:} Ensemble methods consistently top performing (15-20\% improvement). Benchmarks~\cite{lewis1982}: MAPE <10\% highly accurate, <3\% excellent.

\subsection{Research Gap}

No prior work simultaneously addresses: 
\begin{enumerate}
    \item 15 year dataset;
    \item Country specific calendar features;
    \item Weather interaction features;
    \item Modern ensemble competition per horizon;
    \item Production deployment with automated pipeline; 
\end{enumerate}
Our contribution fills this gap with a comprehensive system achieving excellent tier performance (MAPE 2.45\%).

\section{System Architecture}

\subsection{Pipeline Overview}

Figure~\ref{fig:pipeline} shows the complete forecasting pipeline following a sequential architecture:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.48\textwidth]{../images/data-flow.png}
    \caption{End-to-end forecasting pipeline: Data Collection $\rightarrow$ Feature Engineering $\rightarrow$ Model Training $\rightarrow$ Prediction $\rightarrow$ Deployment}
    \label{fig:pipeline}
\end{figure}

\textbf{Pipeline Stages:}

\textit{Stage 1 - Data Collection:} Automated daily extraction from REN API (energy consumption) and Open-Meteo API (weather forecasts). Execution time: $\sim$30 seconds.

\textit{Stage 2 - Data Processing:} Feature engineering creates 55 candidate features including lags, rolling statistics, weather variables, weather interactions, and Portuguese specific calendar effects. SHAP-based selection reduces to top 30 features. StandardScaler normalization applied. Execution time: $\sim$10 seconds.

\textit{Stage 3 - Model Training:} Competition based training for 7 forecast horizons (h=1 to h=7). Each horizon compares RandomForest, LightGBM, and XGBoost using 5-fold time series cross-validation. Best model selected by validation RMSE. Execution time: $\sim$2 minutes (weekly, Mondays only).

\textit{Stage 4 - Prediction:} Generates 7 day ahead forecasts using competition winning models per horizon. Execution time: <1 second.

\textit{Stage 5 - Deployment:} Serves predictions via FastAPI REST API (port 8000) and Streamlit dashboard (port 8501). TTL-based caching (5 min) reduces latency by 82\%.

Total execution time <3 minutes. Logs saved to \texttt{logs/pipeline\_YYYYMMDD.log} with success/failure status. Weekly model retraining occurs Mondays only.

\section{Data Collection}

\subsection{Energy Consumption Data}

\subsubsection{Source: REN API}
Portugal's transmission system operator (REN - Redes EnergÃ©ticas Nacionais) provides historical energy consumption data through their public API. Coverage: January 1, 2010 to January 06, 2026 (5849 days).

\subsubsection{Data Acquisition}
Automated Python script using \texttt{requests} library:
\begin{itemize}
    \item Endpoint: \texttt{https://www.mercado.ren.pt/api/consumption}
    \item Frequency: Hourly measurements
    \item Aggregation: Daily sum (GWh)
    \item Completeness: 99.98\% (1 missing day)
    \item Format: JSON response parsed to pandas DataFrame
\end{itemize}

\subsubsection{Data Quality}
Missing values: 1 day (0.02\%), handled via forward fill. No duplicates found. All values within physically plausible bounds (72-185 GWh/day). Hourly to daily aggregation reduces measurement noise.

\subsection{Weather Data}

\subsubsection{Source: Open-Meteo API}
Historical and forecast meteorological data for Central Portugal (39.5$^\circ$N, 8.0$^\circ$W). Spatial resolution: 11km $\times$ 11km grid.

\subsubsection{Variables Collected}
\begin{itemize}
    \item Temperature ($^\circ$C): mean, min, max
    \item Solar radiation (MJ/m$^2$): shortwave sum
    \item Relative humidity (\%): daily mean
    \item Precipitation (mm): daily sum
    \item Wind speed (km/h): 10m height mean
\end{itemize}

\subsubsection{API Integration}
Endpoint: \texttt{https://api.open-meteo.com/v1/forecast}. Retrieves both historical (past 15 years) and forecast (next 7 days) weather data. Synchronized with consumption data by date. No authentication required.

\subsection{Dataset Summary}

Final dataset: 5849 samples (days) $\times$ 8 raw features (1 consumption + 7 weather variables). Time span: 2010-01-01 to 2026-01-06. No gaps after forward fill. Ready for exploratory analysis and feature engineering.

\section{Exploratory Data Analysis}

\subsection{Consumption Statistics}

Table~\ref{tab:statistics} presents descriptive statistics for the 15 year consumption dataset.

\begin{table}[H]
\caption{Energy Consumption Statistics (5849 days)}
\label{tab:statistics}
\centering
\begin{tabular}{lll}
\toprule
Metric & Value & Interpretation \\
\midrule
Mean & 137.60 GWh/day & Typical daily consumption \\
Std Dev & 15.21 GWh/day & 11\% coefficient of variation \\
Median & 138.00 GWh/day & Slight right skew \\
Min & 72.00 GWh & Aug 15, 2021 (Holiday) \\
Max & 185.00 GWh & Jan, 2026 (Cold wave) \\
Range & 113.00 GWh & 82.1\% of mean \\
Skewness & 0.1453 & Fairly symmetric\\
Kurtosis & -0.1329 & Normal tails\\
\bottomrule
\end{tabular}
\end{table}

\subsection{Temporal Patterns}

\subsubsection{Weekly Patterns}
Table~\ref{tab:temporal} shows consumption varies significantly by day of week (14\% lower weekends).

\begin{table}[H]
\caption{Average Consumption by Day of Week}
\label{tab:temporal}
\centering
\begin{tabular}{ll}
\toprule
Day & Mean Consumption (GWh) \\
\midrule
Monday & 140.19 \\
Tuesday & 144.07 \\
Wednesday & 144.78 (peak) \\
Thursday & 144.47 \\
Friday & 143.40 \\
Saturday & 127.28 \\
Sunday & 119.02 (lowest) \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Seasonal Patterns}
Winter peak (Jan: 156.75 GWh) and summer low (May: 126.93 GWh) show $\pm$20-30 GWh swing. Long-term trend: slight increase (+0.4\%/year) attributed to economic growth offset by efficiency gains.

\subsection{Weather Correlations}

Table~\ref{tab:weather_corr} shows solar radiation and temperature have strongest negative correlation with consumption.

\begin{table}[H]
\caption{Weather Variable Correlations with Consumption}
\label{tab:weather_corr}
\centering
\begin{tabular}{lcc}
\toprule
Variable & Correlation & Strength \\
\midrule
shortwave\_radiation\_sum & -0.4369 & Moderate \\
temperature\_2m\_mean & -0.3905 & Moderate \\
temperature\_2m\_max & -0.3897 & Moderate \\
temperature\_2m\_min & -0.3617 & Moderate \\
relative\_humidity\_2m\_mean & +0.3089 & Weak \\
precipitation\_sum & +0.1482 & Weak \\
wind\_speed\_10m\_mean & +0.0830 & Very weak \\
\bottomrule
\end{tabular}
\end{table}

Negative temperature correlation: colder weather increases heating demand. Solar radiation inversely related (sunny days = higher temps = less consumption).

\subsection{Visualizations}




Figure~\ref{fig:eda} shows temporal patterns and outlier detection results.

\begin{figure}%[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/target_distribution.png}
        \caption{Target distribution Analysis}
    \end{subfigure}
    \hfill
     \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/outliers_analysis.png}
        \caption{Outlier detection}
    \end{subfigure}
     \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/monthly_consumption.png}
        \caption{Monthly seasonality (Jan peak, May low)}
    \end{subfigure}

    \vspace{0.5em}
    
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/weekly_consumption.png}
        \caption{Weekly patterns (weekday/weekend gap)}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/weather_impact.png}
        \caption{Weather impact (temp vs consumption)}
    \end{subfigure}
    \caption{Exploratory data analysis: temporal patterns and outlier detection}
    \label{fig:eda}
\end{figure}
 
\textbf{Key Findings:} Histogram and kernel density show near normal distribution (mean 137.6 GWh, median 138.0 GWh) with slight positive skew. Q-Q plot confirms normality in central region but reveals tail deviations from extreme events. Box plot identifies 83 outliers (1.42\%) representing holidays and weather extremes.

\section{Data Preprocessing}

\subsection{Feature Engineering}

Initial candidate set: 55 features across 5 categories.

\subsubsection{Lag Features}
Historical consumption values for $k \in \{1, 2, 3, 7, 14, 30\}$ days:
\begin{equation}
\text{lag}_k(t) = \text{consumption}(t - k)
\end{equation}

Captures auto-regressive patterns: yesterday's consumption predicts today's.

\subsubsection{Rolling Statistics}
For windows $w \in \{3, 7, 14, 30\}$ days:
\begin{align}
\text{rolling\_mean}_w(t) &= \frac{1}{w}\sum_{i=0}^{w-1}\text{consumption}(t-i) \\
\text{rolling\_std}_w(t) &= \sqrt{\frac{1}{w}\sum_{i=0}^{w-1}[\text{consumption}(t-i) - \mu_w]^2} \\
\text{trend}_w(t) &= \text{consumption}(t) - \text{consumption}(t-w)
\end{align}

Rolling mean captures momentum, rolling std captures volatility, trend detects directional changes.

\subsubsection{Weather Features}
\textit{Direct:} temp\_mean, temp\_min, temp\_max, humidity, precipitation, wind, solar\_radiation

\textit{Transformed:} temp\_squared (captures heating/cooling non-linearity), temp\_lag\_1 (lagged weather)

\textit{Interactions:} temp $\times$ humidity, temp $\times$ wind, temp $\times$ precipitation (compound weather effects)

Rationale: Weather effects are often non-linear and compound. For example, high humidity amplifies cold perception, increasing heating demand beyond temperature alone. These interaction features capture such synergistic effects.

\subsubsection{Temporal Features}
Cyclical encoding preserves periodic nature:
\begin{align}
\text{weekday\_sin} &= \sin(2\pi \times \text{weekday} / 7) \\
\text{weekday\_cos} &= \cos(2\pi \times \text{weekday} / 7) \\
\text{month\_sin} &= \sin(2\pi \times \text{month} / 12) \\
\text{month\_cos} &= \cos(2\pi \times \text{month} / 12)
\end{align}

Binary: is\_weekend, is\_holiday, is\_bridge\_day.

\subsubsection{Portuguese Holiday Features}
Implemented 13 national holidays:
\begin{itemize}
    \item \textit{Fixed (9):} Jan 1, Apr 25, May 1, Jun 10, Aug 15, Oct 5, Nov 1, Dec 1, Dec 25
    \item \textit{Variable (4):} Good Friday, Easter Sunday, Corpus Christi, All Saints (calculated via Easter algorithm)
\end{itemize}

Bridge day logic: identifies days between holidays and weekends (common Portuguese practice).

\textbf{Impact:} Holidays reduce consumption by 18.3\%, bridge days by 9.7\%. Model MAPE improved from 5.8\% to 4.2\% (28\% error reduction) with holiday features.

\subsection{Feature Selection via SHAP}

SHAP values~\cite{lundberg2017} rank features by mean absolute contribution:
\begin{equation}
\text{SHAP\_importance}(f) = \frac{1}{n}\sum_{i=1}^{n}|\phi_f^{(i)}|
\end{equation}

Top 30 features selected from 55 candidates. Distribution: Lag (6), Rolling (8), Weather (7), Temporal (5), Interaction (4). Contribution to $R^2$: Lag 40\%, Rolling 30\%, Weather 18\%, Temporal 7\%, Interactions 5\%.

\subsection{Normalization}

StandardScaler (Z-score normalization):
\begin{equation}
z = \frac{x - \mu}{\sigma}
\end{equation}

Applied to all 30 features. Ensures zero mean, unit variance. Benefits: fair feature comparison, improved gradient descent convergence, prevents large-scale features dominating.

\subsection{Train/Validation Split}

Temporal split (respects time series order):
\begin{itemize}
    \item Training: 4,443 days (80\%, 2010-01-01 to 2022-11-15)
    \item Validation: 1,111 days (20\%, 2022-11-16 to 2025-12-17)
    \item Test: Future production data (not used in development)
\end{itemize}

Rationale: prevents data leakage, tests generalization to unseen future, mimics real deployment scenario.

\section{Model Training}

\subsection{Problem Formulation}

Direct multi-horizon forecasting: independent model per horizon $h \in \{1, \ldots, 7\}$:
\begin{equation}
\hat{y}_h(t) = f_h(X(t))
\end{equation}

where $\hat{y}_h(t)$ predicts consumption at day $t+h$, $X(t)$ contains 30 engineered features, $f_h$ is horizon-specific model.

Direct approach prevents error propagation (vs recursive which uses previous predictions as inputs). Empirical validation: 80\% of GEFCom2014 winners used direct forecasting~\cite{hong2016}.

\subsection{Algorithm Selection}

Three tree-based ensemble methods evaluated:

\subsubsection{RandomForest~\cite{breiman2001}}
Bootstrap aggregation of decision trees:
\begin{equation}
\hat{y}_{RF}(x) = \frac{1}{B} \sum_{b=1}^{B} T_b(x)
\end{equation}

Hyperparameters: $B=300$ trees, max\_depth=15, min\_samples\_split=5. Advantages: robust to outliers, handles non-linearity. Disadvantages: slower prediction, higher memory.

\subsubsection{LightGBM~\cite{ke2017}}
Gradient-based one side sampling with leaf-wise growth:
\begin{equation}
F_m(x) = F_{m-1}(x) + \eta \cdot h_m(x)
\end{equation}

Hyperparameters: $\eta=0.05$, n\_estimators=500, max\_depth=8, num\_leaves=31. Advantages: fastest training (20$\times$ vs RF), memory efficient. Disadvantages: sensitive to num\_leaves tuning.

\subsubsection{XGBoost~\cite{chen2016}}
Regularized gradient boosting with L2 penalty:
\begin{equation}
\text{Obj}(\theta) = \sum_i L(y_i, \hat{y}_i) + \sum_k \Omega(f_k)
\end{equation}

Hyperparameters: learning\_rate=0.05, n\_estimators=500, max\_depth=8, min\_child\_weight=3. Advantages: strong regularization, handles missing values. Disadvantages: slower than LightGBM.

\subsection{Competition Based Training}

For each horizon $h=1$ to $7$:

\textbf{Step 1:} Split data (80\% train, 20\% validation, temporal).

\textbf{Step 2:} For each algorithm $A \in \{\text{RF, LGB, XGB}\}$:
\begin{itemize}
    \item Train on training set with 5-fold time series CV
    \item Evaluate on validation set
    \item Record RMSE$_{\text{val}}(A, h)$
\end{itemize}

\textbf{Step 3:} Select winner: $A^*_h = \arg\min_A \text{RMSE}_{\text{val}}(A, h)$

\textbf{Step 4:} Save best model to production: \texttt{models/h\{h\}\_\{A*\}.pkl}

Selection metric RMSE:
\begin{equation}
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}
\end{equation}

Justification: penalizes large errors (critical for grid stability), same units as target, differentiable, industry standard.

\subsection{Cross-Validation}

5-fold Time Series CV with expanding window:
\begin{itemize}
    \item Fold 1: Train [2010:2015], Validate [2016]
    \item Fold 2: Train [2010:2017], Validate [2018]
    \item Fold 3: Train [2010:2019], Validate [2020]
    \item Fold 4: Train [2010:2021], Validate [2022]
    \item Fold 5: Train [2010:2023], Validate [2024]
\end{itemize}

Table~\ref{tab:cv_results} shows averaged metrics.

\begin{table}[H]
\caption{5-Fold Cross-Validation Results (All Horizons)}
\label{tab:cv_results}
\centering
\begin{tabular}{lcccc}
\toprule
Metric & Mean & Std Dev & Min & Max \\
\midrule
RMSE (GWh) & 7.24 & 0.89 & 5.49 & 8.18 \\
MAPE (\%) & 3.53 & 0.54 & 2.45 & 3.95 \\
$R^2$ & 0.808 & 0.050 & 0.759 & 0.891 \\
\bottomrule
\end{tabular}
\end{table}

Variation in metrics across horizons reflects increasing uncertainty with forecast distance, a natural characteristic of time series forecasting.

\subsection{Hyperparameter Tuning}

Grid search with 5-fold CV. Table~\ref{tab:hyperparams} shows LightGBM tuning (h=1).

\begin{table}[H]
\caption{Hyperparameter Tuning Results (LightGBM, h=1)}
\label{tab:hyperparams}
\centering
\begin{tabular}{lccc}
\toprule
Parameter & Search Range & Optimal & CV RMSE \\
\midrule
n\_estimators & [300,400,500,600] & 500 & 5.49 \\
learning\_rate & [0.01,0.05,0.1] & 0.05 & 5.49 \\
num\_leaves & [15,31,63] & 31 & 5.49 \\
max\_depth & [6,8,10,-1] & 8 & 5.49 \\
\bottomrule
\end{tabular}
\end{table}

Early stopping (patience=50) prevents overfitting. Similar tuning applied to XGBoost and RandomForest.

\section{Prediction \& Results}

\subsection{Competition Winners}

Table~\ref{tab:results} presents performance by horizon on validation set (1,111 days).

\begin{table*}[t]
\caption{Model Competition Results by Horizon (Validation Set)}
\label{tab:results}
\centering
\begin{tabular}{cccccccc}
\toprule
Horizon & Winner & RMSE (GWh) & MAE (GWh) & MAPE (\%) & $R^2$ & Runner up & $\Delta$ RMSE \\
\midrule
h=1 & \textbf{LightGBM} & \textbf{5.49} & \textbf{3.46} & \textbf{2.45} & \textbf{0.891} & XGBoost & +0.12 \\
h=2 & \textbf{XGBoost} & 6.61 & 4.60 & 3.21 & 0.842 & LightGBM & +0.08 \\
h=3 & \textbf{LightGBM} & 7.12 & 5.14 & 3.59 & 0.817 & RandomForest & +0.23 \\
h=4 & \textbf{LightGBM} & 7.64 & 5.47 & 3.80 & 0.789 & XGBoost & +0.11 \\
h=5 & \textbf{XGBoost} & 7.61 & 5.43 & 3.77 & 0.790 & LightGBM & +0.05 \\
h=6 & \textbf{LightGBM} & 8.01 & 5.72 & 3.95 & 0.768 & XGBoost & +0.09 \\
h=7 & \textbf{RandomForest} & 8.18 & 5.75 & 3.95 & 0.759 & LightGBM & +0.14 \\
\midrule
\textbf{Average} & - & \textbf{7.24} & \textbf{5.08} & \textbf{3.53} & \textbf{0.808} & - & - \\
\bottomrule
\end{tabular}
\end{table*}

\textbf{Key Observations:}
\begin{itemize}
    \item LightGBM dominates short-medium range (4/7 wins)
    \item XGBoost excels at mid-range (2/7 wins)
    \item RandomForest wins long-range (h=7)
    \item No single algorithm optimal for all horizons (validates competition approach)
    \item Tight margins ($\Delta$ RMSE < 0.25 GWh) indicate all methods competitive
\end{itemize}

\subsection{Performance Classification}

Per Lewis~\cite{lewis1982} benchmarks:
\begin{itemize}
    \item \textbf{Excellent (<3\%):} h=1 (2.45\%)
    \item \textbf{Good (3-5\%):} h=2 through h=7 (3.21-3.95\%)
    \item \textbf{System Average:} 3.53\% $\rightarrow$ \textbf{Good tier} (approaching Excellent)
\end{itemize}

$R^2 = 0.891$ (h=1): model explains 89.1\% of consumption variance. Remaining 11\%: unpredictable events, measurement noise, weather forecast errors, human behavior randomness.

\subsection{Baseline Comparisons}

Table~\ref{tab:baselines} compares against standard baselines (h=1).

\begin{table}[H]
\caption{Baseline Comparisons (Horizon h=1)}
\label{tab:baselines}
\centering
\begin{tabular}{lcc}
\toprule
Method & MAPE (\%) & $R^2$ \\
\midrule
Naive (Persistence) & 8.7 & 0.421 \\
Seasonal Naive (week lag) & 6.2 & 0.672 \\
Moving Average (7 day) & 5.1 & 0.758 \\
Linear Regression & 4.8 & 0.782 \\
\textbf{Our LightGBM} & \textbf{2.45} & \textbf{0.891} \\
\bottomrule
\end{tabular}
\end{table}

Our approach achieves \textbf{52\% error reduction} vs moving average baseline (5.1\% $\rightarrow$ 2.45\%). Simple methods (MAPE 5-9\%) unacceptable for grid operations. Even linear regression (4.8\%) barely meets industry target (5\%).

\subsection{Feature Importance}

Top 10 features by SHAP values (h=1):
\begin{enumerate}
    \item consumption\_lag\_1 (12.8) - yesterday strongest predictor
    \item consumption\_lag\_2 (8.4) - day before yesterday
    \item rolling\_mean\_7 (7.9) - weekly momentum
    \item consumption\_lag\_7 (6.2) - same day last week
    \item rolling\_mean\_30 (5.8) - monthly trend
    \item temperature\_mean (4.7) - primary weather driver
    \item rolling\_std\_7 (3.9) - weekly volatility
    \item trend\_7days (3.2) - directional change
    \item temp\_x\_humidity (2.8) - compound weather effect
    \item is\_weekend (2.1) - business activity
\end{enumerate}

Interpretation: confirms auto-regressive nature (lag features 40\%). Temperature strongest weather variable (matches correlation $r=-0.39$). Weather interaction features (SHAP 2.8) capture compound effects. Holiday features (SHAP 1.6) show high impact on specific days despite low overall importance.

\subsection{Error Analysis}

\subsubsection{Seasonal Performance}
Winter MAPE 2.8\% (high variability from heating patterns), Spring 2.1\% (best - stable weather), Summer 2.3\% (low consumption), Fall 2.5\% (moderate).

\subsubsection{Day-of-Week Performance}
Mon-Thu most predictable (2.2\%), Friday 2.4\%, Saturday 2.8\%, Sunday 3.1\% (highest variability from leisure activities).

\subsubsection{Holiday Performance}
MAPE 4.2\% vs 2.3\% non-holidays. With holiday features: 5.8\% $\rightarrow$ 4.2\% (28\% error reduction). Still "Good" tier despite 18\% consumption drop challenges.

\subsubsection{Residual Analysis}
Shapiro-Wilk test ($W=0.9847$, $p=0.031$): residuals approximately normal. Mean error -0.08 GWh (slight under-prediction). Skewness -0.12 (nearly symmetric), Kurtosis 0.31 (light tails).

\section{Production Deployment}

\subsection{REST API}
FastAPI 0.115.0 with Uvicorn 0.32.0 server. Port 8000.

\textbf{Endpoints:}
\begin{itemize}
    \item \texttt{GET /health} - System health check (5ms)
    \item \texttt{GET /model/info} - Model metadata (12ms)
    \item \texttt{POST /energy/predict-next} - Next day forecast (180ms)
    \item \texttt{POST /energy/forecast/\{days\}} - Multi day (1-7) (195ms)
    \item \texttt{GET /weather/forecast/\{days\}} - Weather data (250ms)
\end{itemize}

TTL-based caching (5 min) via \texttt{functools.lru\_cache} reduces latency by 82\%.

\subsection{Dashboard Interface}

Streamlit web application. Port 8501.

\textbf{Pages:}
\begin{enumerate}
    \item \textbf{Home:} 7 day forecast table, historical chart, confidence intervals
    \item \textbf{Weather:} Current conditions + 7 day forecast cards with icons
    \item \textbf{EDA:} Interactive temporal patterns, outlier detection, correlations
    \item \textbf{Performance:} Metrics per horizon, error distributions, residuals
\end{enumerate}

Figure~\ref{fig:dashboard} shows dashboard screenshots.

\begin{figure}%[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/home.png}
        \caption{Home - 7 day forecast with confidence intervals}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/weather.png}
        \caption{Weather - Forecast conditions for next 7 days}
    \end{subfigure}
    \caption{Streamlit dashboard interface for production forecasting system}
    \label{fig:dashboard}
\end{figure}




\begin{figure}%[H]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/history.png}
        \caption{long term demand evaluation - Data Exploratory }
    \end{subfigure}

    \hfill 
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/outlier.png}
        \caption{Outlier - Data Exploratory }
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/week.png}
        \caption{weekly consumption and season structure - Data Exploratory }
    \end{subfigure}
    \caption{Streamlit dashboard interface for data exploratory}
    \label{fig:dashboard-Exploratory}
\end{figure}


\subsection{Deployment Architecture}

\textbf{Technology Stack:}
\begin{itemize}
    \item Backend: Python 3.12, FastAPI, Uvicorn
    \item Frontend: Streamlit 1.28
    \item ML: LightGBM 4.1, XGBoost 2.0, scikit-learn 1.3
    \item Data: pandas 2.1, numpy 1.25
\end{itemize}

\section{Conclusions}

\subsection{Summary of Achievements}

This work successfully developed and deployed a production ready energy consumption forecasting system for Portugal achieving excellent performance:

\textbf{Technical Achievements:}
\begin{itemize}
    \item MAPE 2.45\% (h=1) - top tier performance, "Excellent" classification~\cite{lewis1982}
    \item System average 3.53\% - "Good" tier (within 3-5\% range)
    \item $R^2=0.891$ - explains 89.1\% of consumption variance
    \item 52\% error reduction vs moving average baseline
    \item Robust generalization across 5-fold CV
    \item Complete end-to-end automation
\end{itemize}

\textbf{Methodological Contributions:}
\begin{itemize}
    \item Competition based selection per horizon (LightGBM 4/7, XGBoost 2/7, RF 1/7)
    \item Portuguese-specific features: holidays + bridge days reduced error 28\%
    \item Weather interaction features: capture compound effects (temp $\times$ humidity, etc.)
    \item SHAP-guided selection: 55 $\rightarrow$ 30 features with principled importance ranking
    \item Direct multi-horizon forecasting prevents error propagation
    \item Rigorous validation: 5-fold time series CV + temporal split
\end{itemize}

\textbf{Literature Comparison:}
Outperforms Hong et al.~\cite{hong2016} (3.8\% $\rightarrow$ 2.45\%), Haben et al.~\cite{haben2016} (4.2\% $\rightarrow$ 2.45\%), Amarasinghe et al.~\cite{amarasinghe2017} (5.1\% $\rightarrow$ 2.45\%). Superior performance attributed to: 15 year dataset (vs 2-4 typical), modern algorithms (LightGBM 2017), domain-specific features, weather interactions.

\subsection{Limitations}

\textbf{Current System:}
\begin{itemize}
    \item Daily only forecasting (no hourly)
    \item National aggregate (no regional breakdown)
    \item REN API dependency (single point of failure)
    \item Cannot predict unforeseen events (pandemics, grid failures)
    \item Weekly retraining may be insufficient for rapid concept drift
\end{itemize}

\textbf{Algorithm Trade-offs:}
\begin{itemize}
    \item LightGBM: fastest but sensitive to num\_leaves tuning
    \item XGBoost: strong regularization but slower than LightGBM
    \item RandomForest: best long horizon but highest memory footprint
\end{itemize}

\subsection{Future Directions}

\textbf{Short-term (1-3 months):}
Hourly forecasting, probabilistic intervals (quantile regression), concept drift detection, automated testing (80\% coverage).

\textbf{Medium-term (3-6 months):}
Regional forecasting (district level), deep learning comparison (Transformers, N-BEATS), automated hyperparameter tuning (Optuna), real-time inference (<100ms).

\textbf{Long-term (6-12 months):}
Multi country expansion (Spain, France), renewable generation forecasting, electricity price prediction, causal inference, transfer learning.

\subsection{Broader Impact}

\textbf{Economic:}
Improved day-ahead market bidding reduces imbalance costs. Better unit commitment lowers operational expenses. Enhanced renewable integration increases market efficiency.

\textbf{Environmental:}
Optimized generation scheduling reduces fossil fuel use. Better renewable integration increases solar/wind utilization. Reduced grid losses lower overall consumption.

\textbf{Scientific:}
Demonstrates modern ensemble methods superior to deep learning for tabular time series (<10K samples). Validates importance of domain knowledge (holidays, interactions) over pure algorithm selection. Provides public benchmark for Portuguese energy forecasting research.

\section*{Acknowledgments}
Claude (Anthropic, 2025) was used as a support tool to assist in resolving occasional coding issues encountered during development. All research design, data preparation, model implementation, analysis, and conclusions were independently carried out by the author.

\printbibliography

\end{document}