\documentclass[journal]{IEEEtran}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{caption}
\usepackage{url}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[style=ieee]{biblatex}
\usepackage{float}
\usepackage{subcaption}

\addbibresource{references.bib}

\begin{document}

\title{Energy Consumption Forecasting for Portugal Using Ensemble Machine Learning}

\author{Domingos Kaquepa Luciano Graciano\\
\small Department of Electronics, Telecommunications and Informatics\\
\small University of Aveiro, Portugal\\
\small Specialization Program in Machine Learning and Data Analysis\\
\small Email: dkgraciano92@ua.pt\\}

\maketitle

\begin{abstract}
This paper presents a machine learning system for daily energy consumption forecasting in Portugal that achieves a Mean Absolute Percentage Error (MAPE) of 2.45\% for next day predictions. We employed a competition based ensemble approach, comparing RandomForest, LightGBM, and XGBoost algorithms across 7 forecast horizons. The system integrates over 15 years of historical consumption data from Portugal's national grid operator (REN) with weather data from the Open-Meteo API. Our implementation includes advanced feature engineering with Portuguese specific holiday detection and weather interaction features. Using direct multi horizon forecasting with 5-fold cross-validation, our best model (LightGBM for horizon +1) achieves $R^{2} = 0.891$, outperforming published baselines by 52\%. The complete system runs as a production REST API with automated daily updates, demonstrating how domain specific feature engineering combines effectively with modern gradient boosting methods for operational energy forecasting.
\end{abstract}

\begin{IEEEkeywords}
Energy forecasting, Time series prediction, Ensemble learning, LightGBM, XGBoost, Feature engineering, Portugal.
\end{IEEEkeywords}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Motivation}

Portugal faces unique challenges in energy forecasting. The country's grid combines substantial renewable penetration from wind, solar, and hydro sources with conventional thermal generation, creating complex demand dynamics that require precise forecasting. Grid operators need accurate predictions not just for operational stability but also for economic efficiency in the European day ahead electricity market, where forecasts must be submitted 12-36 hours in advance. Getting these predictions right matters: inaccurate forecasts lead to imbalance penalties, suboptimal unit commitment, and inefficient use of renewable resources.

\subsection{Problem Statement}

We frame this as a multi output regression problem. Given 30 engineered features including historical consumption lags, rolling statistics, weather variables, temporal features, and calendar effects specific to Portugal the system predicts daily consumption values (in GWh) for the next seven days. The dataset spans 5849 days with complex non linear relationships, seasonal patterns, holiday effects, and weather dependencies that standard linear approaches cannot capture adequately.

\subsection{Objectives}

Our work pursues four specific goals. First, achieve MAPE below 5\% for next day forecasts, which represents industry best practice. Second, develop a complete multi horizon system covering 1-7 days ahead rather than just next day predictions. Third, systematically compare performance across three modern ensemble methods to understand which algorithms excel at different forecast horizons. Fourth, deploy a production ready system with automated pipelines rather than just academic prototype code.

\subsection{Contributions}

This work represents the first comprehensive, production ready energy forecasting system specifically designed for Portugal. Several aspects distinguish our approach from existing literature. We work with 15 years of data compared to the 2-5 year datasets typical in published research. Our feature engineering incorporates Portuguese specific calendar features including national holidays and "bridge days" (the Portuguese practice of taking days off between holidays and weekends). We introduce weather interaction features that capture compound effects like how humidity amplifies cold perception. The system implements per horizon algorithm competition rather than assuming one algorithm works best everywhere. Finally, we provide complete automation with REST API deployment, not just experimental results.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Energy Forecasting Literature}

Table~\ref{tab:literature} positions our work within the broader energy forecasting landscape. 

\begin{table}[H]
\caption{Comparative Summary of Related Work}
\label{tab:literature}
\centering
\footnotesize
\begin{tabular}{ccccc}
\toprule
Study & Geography & Dataset & MAPE & Method \\
\midrule
Hong et al.~\cite{hong2016} & USA & 4 years & 3.8\% & GBM \\
Haben et al.~\cite{haben2016} & UK & 2 years & 4.2\% & ANN \\
Amarasinghe et al.~\cite{amarasinghe2017} & Australia & 3 years & 5.1\% & LSTM \\
Lago et al.~\cite{lago2018} & Belgium & 3 years & 3.9\% & DNN+ARIMA \\
\textbf{This Work} & \textbf{Portugal} & \textbf{15 years} & \textbf{2.45\%} & \textbf{LightGBM} \\
\bottomrule
\end{tabular}
\end{table}

Several key findings emerge from the literature. The GEFCom 2014 competition~\cite{hong2016} established that direct forecasting training independent models per horizon outperforms recursive approaches where predictions feed into future predictions. About 80\% of top performing teams adopted this strategy. Gradient boosting methods achieved MAPE between 2.5-4.5\%, with feature engineering proving more impactful than algorithm selection.

Research on UK smart meters~\cite{haben2016} revealed typical feature importance distributions: lags contribute 40\%, weather variables 25\%, and calendar effects 15\%. Customer segmentation improved accuracy, though that approach doesn't translate directly to national level forecasting.

Deep learning studies present mixed results. LSTM networks~\cite{amarasinghe2017} achieved MAPE around 5.1\% but required large datasets, substantial GPU training time (4+ hours), and offered limited interpretability. Recent meta analyses~\cite{shwartz2022} suggest tree based methods actually outperform deep learning for tabular datasets below 10K samples, which describes most practical energy forecasting scenarios.

Hybrid approaches like DNN+ARIMA combinations~\cite{lago2018} reached 3.9\% MAPE but increased system complexity substantially. Standalone XGBoost proved competitive at 4.1\% with simpler architecture. Meta analyses~\cite{weron2014} consistently show ensemble methods delivering 15-20\% improvements over single models. The Lewis benchmark system~\cite{lewis1982} classifies forecasting performance: MAPE below 10\% indicates high accuracy, while below 3\% represents excellent performance.

\subsection{Research Gap}

No prior work simultaneously addresses five key requirements: 15-year historical datasets, country specific calendar features, weather interaction terms, per horizon algorithm competition, and production deployment with automated pipelines. Our contribution fills this gap while achieving excellent tier performance at 2.45\% MAPE.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{System Architecture}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Pipeline Overview}

Figure~\ref{fig:pipeline} illustrates our complete forecasting pipeline, which follows a sequential architecture designed for both daily operation and weekly model retraining.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.48\textwidth]{../images/data-flow.png}
    \caption{End-to-end forecasting pipeline: Data Collection $\rightarrow$ Feature Engineering $\rightarrow$ Model Training $\rightarrow$ Prediction $\rightarrow$ Deployment}
    \label{fig:pipeline}
\end{figure}

The pipeline operates in five stages. Stage 1 performs automated daily extraction from two sources: the REN API provides energy consumption data while Open-Meteo supplies weather forecasts. This stage completes in approximately 30 seconds. Stage 2 handles feature engineering, creating 55 candidate features from the raw data including lags, rolling statistics, weather variables, interactions, and Portuguese calendar effects. SHAP based selection then reduces these to the top 30 features before StandardScaler normalization. This processing takes about 10 seconds.

Stage 3 implements model training, but only on Mondays to balance freshness with computational costs. For each of seven forecast horizons (h=1 through h=7), the system trains three algorithms RandomForest, LightGBM, and XGBoost using 5-fold time series cross-validation. The algorithm with lowest validation RMSE wins that horizon. Training takes roughly 2 minutes on standard hardware. Stage 4 generates predictions almost instantly (<1 second) using the winning models. Stage 5 serves these predictions through a FastAPI REST API on port 8000 and an interactive Streamlit dashboard on port 8501. TTL based caching with 5 minute expiration reduces latency by 82\% for repeated requests.

Total execution time stays under 1 minutes even during Monday's full training cycle. The system logs all operations to \texttt{logs/pipeline\_YYYYMMDD.log} with clear success/failure status, making debugging straightforward when issues arise.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Collection}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Energy Consumption Data}

Portugal's transmission system operator, REN (Redes Energéticas Nacionais), provides historical energy consumption through their public API. We collected data spanning January 1, 2010 to January 6, 2026 5849 days in total. The API endpoint (\texttt{https://www.mercado.ren.pt/api/consumption}) returns hourly measurements which we aggregate to daily sums measured in GWh.

Data quality proved excellent. We found only one missing day (0.02\% of the dataset) which we handled through forward fill. No duplicates appeared, and all values fell within physically plausible bounds of 72-185 GWh/day. The hourly to daily aggregation actually helps reduce measurement noise compared to working with raw hourly data.

\subsection{Weather Data}

Historical and forecast meteorological data comes from the Open-Meteo API, covering Central Portugal at coordinates 39.5$^\circ$N, 8.0$^\circ$W with 11km × 11km spatial resolution. We collect seven weather variables: temperature (mean, min, max in $^\circ$C), solar radiation (shortwave sum in MJ/m$^{2}$), relative humidity (daily mean percentage), precipitation (daily sum in mm), and wind speed (10m height mean in km/h).

The API endpoint (\texttt{https://api.open-meteo.com/v1/forecast}) provides both historical archives (past 15 years) and forecasts (next 7 days), synchronized with consumption data by date. No authentication is required, simplifying deployment.\\

\subsection{Dataset Summary}

Our final raw dataset contains 5849 samples (days) × 8 features (1 consumption + 7 weather variables). This clean dataset provides the foundation for exploratory analysis and feature engineering.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exploratory Data Analysis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Consumption Statistics}

Table~\ref{tab:statistics} summarizes 15 years of energy consumption patterns in Portugal.

\begin{table}[H]
\caption{Energy Consumption Statistics (5849 days)}
\label{tab:statistics}
\centering
\begin{tabular}{lll}
\toprule
Metric & Value & Interpretation \\
\midrule
Mean & 137.60 GWh/day & Typical daily consumption \\
Std Dev & 15.21 GWh/day & 11\% coefficient of variation \\
Median & 138.00 GWh/day & Slight right skew \\
Min & 72.00 GWh & Aug 15, 2021 (Holiday) \\
Max & 185.00 GWh & Jan, 2026 (Cold wave) \\
Range & 113.00 GWh & 82.1\% of mean \\
Skewness & 0.1453 & Fairly symmetric\\
Kurtosis & -0.1329 & Normal tails\\
\bottomrule
\end{tabular}
\end{table}

Daily consumption averages 137.6 GWh with standard deviation of 15.21 GWh, yielding an 11\% coefficient of variation. The distribution appears fairly symmetric (skewness 0.15) with normal tails (kurtosis -0.13), though the Shapiro-Wilk test rejects perfect normality due to outliers at both extremes. The minimum of 72 GWh occurred on a major holiday when industrial activity ceased, while the maximum of 185 GWh coincided with a January 2026 cold wave. This 113 GWh range represents substantial variation over 80\% of the mean driven primarily by seasonal heating patterns.

\subsection{Distribution and Outliers}

Figure~\ref{fig:distribution_outliers} examines the consumption distribution from multiple statistical perspectives and identifies outliers within the time series.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/target_distribution.png}
        \caption{Distribution analysis: histogram, kernel density, Q-Q plot, and box plot}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/outliers_analysis.png}
        \caption{Time series with outliers highlighted (IQR bounds: 101-173 GWh)}
    \end{subfigure}
    \caption{Statistical distribution analysis and outlier detection across the 15-year dataset}
    \label{fig:distribution_outliers}
\end{figure}

Panel (a) reveals near normal distribution centered at 137.6 GWh. The kernel density estimate shows a clean unimodal peak, while the Q-Q plot confirms good fit in the central region with deviations only in the tails. The box plot identifies 83 outliers (1.42\% of data): 12 low outliers below 101 GWh and 71 high outliers above 173 GWh.

Panel (b) places these outliers in temporal context. Low outliers (red circles) scatter throughout the timeline, typically corresponding to major holidays Christmas, New Year, Easter when industrial activity largely stops. High outliers (orange circles) concentrate in recent years (2020-2026), reflecting extreme weather events and rising baseline consumption. A notable cluster appears in 2025-2026, suggesting intensified heating demand during that period. We retained all outliers for training since they represent legitimate operational scenarios the forecasting system must handle in production.

\subsection{Temporal Patterns}

Weather correlations appear in Table~\ref{tab:weather_corr}. Solar radiation shows the strongest negative correlation with consumption (-0.44), followed by temperature variables (-0.36 to -0.39). These negative relationships make physical sense: sunny, warm days reduce heating demand. Humidity shows weaker positive correlation (+0.31), possibly because humid conditions amplify cold perception. Wind and precipitation exhibit minimal correlation.

\begin{table}[H]
\caption{Weather Variable Correlations with Consumption}
\label{tab:weather_corr}
\centering
\begin{tabular}{lcc}
\toprule
Variable & Correlation & Strength \\
\midrule
shortwave\_radiation\_sum & -0.4369 & Moderate \\
temperature\_2m\_mean & -0.3905 & Moderate \\
temperature\_2m\_max & -0.3897 & Moderate \\
temperature\_2m\_min & -0.3617 & Moderate \\
relative\_humidity\_2m\_mean & +0.3089 & Weak \\
precipitation\_sum & +0.1482 & Weak \\
wind\_speed\_10m\_mean & +0.0830 & Very weak \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:consumption_pattern} reveals distinct patterns across weekly and seasonal cycles.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/weekly_consumption.png}
        \caption{Average consumption by day of week}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../code/Exploratory_result/monthly_consumption.png}
        \caption{Monthly consumption distribution}
    \end{subfigure}
    \caption{Temporal consumption patterns showing weekly cycles and seasonal variation}
    \label{fig:consumption_pattern}
\end{figure}

Weekdays maintain stable consumption around 143-145 GWh with Wednesday slightly higher at 144.8 GWh. Saturday drops to 127.3 GWh while Sunday falls further to 119.0 GWh a 14\% weekend reduction reflecting ceased industrial operations and reduced commercial activity. This strong weekly signal validates including cyclical weekday features and binary weekend indicators in our model.

Seasonal patterns emerge clearly in the monthly box plots. Winter months (January, February, December) show highest median consumption with January peaking near 157 GWh, driven by heating demand. Spring's rising temperatures bring declining consumption, with May reaching the annual minimum around 127 GWh. Summer maintains moderate consumption despite Portugal's mild maritime climate requiring little air conditioning. Fall shows gradual increase preparing for winter. Box plot spreads indicate higher variability in winter (IQR $\approx$ 20 GWh) versus summer (IQR $\approx$ 15 GWh), reflecting temperature dependent heating patterns.

Figure~\ref{fig:weather_impact} examines temperature's relationship with consumption more closely.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{../code/Exploratory_result/weather_impact.png}
    \caption{Temperature vs consumption scatter plot (n=5849 days) with linear regression fit showing moderate negative correlation ($r=-0.39$, $p<0.001$)}
    \label{fig:weather_impact}
\end{figure}

The scatter plot confirms moderate negative correlation ($r=-0.39$). As temperature rises from 5$^\circ$C to 25$^\circ$C, consumption typically decreases from 160 GWh to 120 GWh a 25\% reduction. The relationship shows non linear characteristics: steeper slope below 10$^\circ$C (heating dominated regime) and flatter slope above 20$^\circ$C (minimal cooling demand). Substantial scatter around the regression line ($\pm$20 GWh at any temperature) indicates temperature alone explains only 15\% of variance. This justifies our multi feature approach combining lags, calendar effects, and other weather variables beyond simple temperature.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Preprocessing}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Feature Engineering}

We engineered 55 candidate features across five categories, then used SHAP analysis to select the most important 30.

\textbf{Lag features} capture auto regressive patterns using consumption from k days ago where k $\in$ \{1, 2, 3, 7, 14, 30\}:
\begin{equation}
\text{lag}_k(t) = \text{consumption}(t - k)
\end{equation}

Yesterday's consumption proves the strongest predictor, with influence declining at longer lags.

\textbf{Rolling statistics} summarize recent trends. For windows w $\in$ \{3, 7, 14, 30\} days, we compute:
\begin{align}
\text{rolling\_mean}_w(t) &= \frac{1}{w}\sum_{i=0}^{w-1}\text{consumption}(t-i) \\
\text{rolling\_std}_w(t) &= \sqrt{\frac{1}{w}\sum_{i=0}^{w-1}[\text{consumption}(t-i) - \mu_w]^2} \\
\text{trend}_w(t) &= \text{consumption}(t) - \text{consumption}(t-w)
\end{align}

Rolling means capture momentum, standard deviations measure volatility, and trends detect directional changes.

\textbf{Weather features} include direct measurements (temp\_mean, temp\_min, temp\_max, humidity, precipitation, wind, solar\_radiation), transformations (temp\_squared captures heating/cooling non linearity, temp\_lag\_1 accounts for delayed effects), and interactions (temp × humidity, temp × wind, temp × rain). These interactions matter because weather effects compound. High humidity amplifies cold perception, increasing heating demand beyond what temperature alone predicts.

\textbf{Temporal features} use cyclical encoding to preserve periodicity:
\begin{align}
\text{weekday\_sin} &= \sin(2\pi \times \text{weekday} / 7) \\
\text{weekday\_cos} &= \cos(2\pi \times \text{weekday} / 7) \\
\text{month\_sin} &= \sin(2\pi \times \text{month} / 12) \\
\text{month\_cos} &= \cos(2\pi \times \text{month} / 12)
\end{align}

Binary features flag weekends, holidays, and bridge days.

\textbf{Portuguese holiday features} proved particularly valuable. We implemented 13 national holidays: 9 fixed dates (Jan 1, Apr 25, May 1, Jun 10, Aug 15, Oct 5, Nov 1, Dec 1, Dec 25) and 4 variable dates computed from Easter (Good Friday, Easter Sunday, Corpus Christi, All Saints). Bridge day logic identifies days between holidays and weekends—a common Portuguese practice where people extend holiday breaks. These features reduced holiday period forecasting error by 28\% (from 5.8\% to 4.2\% MAPE), demonstrating how country specific domain knowledge outperforms generic calendar features.

\subsection{Feature Selection via SHAP}

SHAP values~\cite{lundberg2017} rank features by mean absolute contribution to predictions:
\begin{equation}
\text{SHAP\_importance}(f) = \frac{1}{n}\sum_{i=1}^{n}|\phi_f^{(i)}|
\end{equation}

This analysis reduced our 55 candidates to 30 selected features with clear distribution: lags (6), rolling statistics (8), weather (7), temporal (5), interactions (4). Contribution to total $R^{2}$ breaks down as: lags 40\%, rolling statistics 30\%, weather 18\%, temporal 7%, interactions 5\%. This principled selection process ensures every feature earns its place through demonstrated predictive power.

\subsection{Normalization and Data Splitting}

StandardScaler applies Z-score normalization:
\begin{equation}
z = \frac{x - \mu}{\sigma}
\end{equation}

This centers all features at zero mean with unit variance, ensuring fair comparison during training and improving gradient descent convergence.

We split data temporally to respect time series ordering: 4679 days (80\%, 2010-01-01 to 2022-11-15) for training and 1170 days (20\%, 2022-11-16 to 2026-01-06) for testing. This prevents data leakage while testing generalization to genuinely unseen future periods, mimicking real deployment scenarios.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Model Training}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Problem Formulation}

We adopt direct multi horizon forecasting where independent models handle each horizon h $\in$ \{1, ..., 7\}:
\begin{equation}
\hat{y}_h(t) = f_h(X(t))
\end{equation}

Here $\hat{y}_h(t)$ predicts consumption at day t+h, X(t) contains our 30 engineered features, and $f_h$ represents the horizon specific model. This approach prevents error propagation compared to recursive methods that feed predictions into future predictions. GEFCom2014 validated this strategy: 80\% of winning teams used direct forecasting~\cite{hong2016}.

\subsection{Algorithm Comparison}

We evaluated three tree based ensemble methods, each with distinct characteristics.

\textbf{RandomForest}~\cite{breiman2001} averages predictions from bootstrap aggregated decision trees:
\begin{equation}
\hat{y}_{RF}(x) = \frac{1}{B} \sum_{b=1}^{B} T_b(x)
\end{equation}

We configured 300 trees with max\_depth=15 and min\_samples\_split=5. RandomForest handles outliers well and captures non linearity naturally, though it requires more memory and runs slower than boosting methods.

\textbf{LightGBM}~\cite{ke2017} employs gradient based one side sampling with leaf wise growth:
\begin{equation}
F_m(x) = F_{m-1}(x) + \eta \cdot h_m(x)
\end{equation}
Using learning rate $\eta$=0.05, 500 estimators, max\_depth=8, and num\_leaves=31

\textbf{XGBoost}~\cite{chen2016} adds L2 regularization to gradient boosting:
\begin{equation}
\text{Obj}(\theta) = \sum_i L(y_i, \hat{y}_i) + \sum_k \Omega(f_k)
\end{equation}

With learning\_rate=0.05, 500 estimators, max\_depth=8, and min\_child\_weight=3, XGBoost provides strong regularization and robust handling of missing values, though it runs 2-3× slower than LightGBM.

\subsection{Competition Based Training}

For each horizon, we run a four step competition. First, split data temporally (80\% train, 20\% validation). Second, train each algorithm (RF, LightGBM, XGBoost) using 5-fold time series cross-validation on the training set. Third, evaluate all candidates on the validation set and record RMSE. Fourth, promote the winner with lowest RMSE to production.

We selected RMSE as the primary metric because it penalizes large errors (critical for grid stability), maintains the same units as our target variable, supports mathematical optimization, and represents industry standard practice:
\begin{equation}
\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}
\end{equation}

\subsection{Cross-Validation Protocol}

Our 5-fold expanding window time series CV prevents data leakage while testing generalization:
\begin{itemize}
    \item Fold 1: Train [2010:2015], Validate [2016]
    \item Fold 2: Train [2010:2017], Validate [2018]
    \item Fold 3: Train [2010:2019], Validate [2020]
    \item Fold 4: Train [2010:2021], Validate [2022]
    \item Fold 5: Train [2010:2023], Validate [2024]
\end{itemize}

Table~\ref{tab:cv_results} summarizes averaged performance across all horizons.

\begin{table}[H]
\caption{5-Fold Cross-Validation Results (All Horizons)}
\label{tab:cv_results}
\centering
\begin{tabular}{lcccc}
\toprule
Metric & Mean & Std Dev & Min & Max \\
\midrule
RMSE (GWh) & 7.24 & 0.89 & 5.49 & 8.18 \\
MAPE (\%) & 3.53 & 0.54 & 2.45 & 3.95 \\
$R^2$ & 0.808 & 0.050 & 0.759 & 0.891 \\
\bottomrule
\end{tabular}
\end{table}

Metric variation across horizons follows expected patterns: uncertainty naturally increases with forecast distance. The relatively small standard deviations indicate stable performance across different time periods.

\subsection{Hyperparameter Tuning}

We performed grid search with 5-fold CV for each algorithm. Table~\ref{tab:hyperparams} shows LightGBM tuning results for horizon h=1 as an example.

\begin{table}[H]
\caption{Hyperparameter Tuning Results (LightGBM, h=1)}
\label{tab:hyperparams}
\centering
\begin{tabular}{lccc}
\toprule
Parameter & Search Range & Optimal & CV RMSE \\
\midrule
n\_estimators & [300,400,500,600] & 500 & 5.49 \\
learning\_rate & [0.01,0.05,0.1] & 0.05 & 5.49 \\
num\_leaves & [15,31,63] & 31 & 5.49 \\
max\_depth & [6,8,10,-1] & 8 & 5.49 \\
\bottomrule
\end{tabular}
\end{table}

Early stopping with patience=50 prevented overfitting during training. Similar tuning processes applied to XGBoost and RandomForest, customized to each algorithm's specific hyperparameter space.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results and Performance Analysis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Per Horizon Competition Winners}

Table~\ref{tab:results} presents final performance across all seven forecast horizons on our held out test set.

\begin{table*}[t]
\caption{Model Competition Results by Horizon (Test Set, 1170 days)}
\label{tab:results}
\centering
\begin{tabular}{cccccccc}
\toprule
Horizon & Winner & RMSE (GWh) & MAE (GWh) & MAPE (\%) & $R^2$ & Runner up & $\Delta$ RMSE \\
\midrule
h=1 & \textbf{LightGBM} & \textbf{5.49} & \textbf{3.46} & \textbf{2.45} & \textbf{0.891} & XGBoost & +0.12 \\
h=2 & \textbf{XGBoost} & 6.61 & 4.60 & 3.21 & 0.842 & LightGBM & +0.08 \\
h=3 & \textbf{LightGBM} & 7.12 & 5.14 & 3.59 & 0.817 & RandomForest & +0.23 \\
h=4 & \textbf{LightGBM} & 7.64 & 5.47 & 3.80 & 0.789 & XGBoost & +0.11 \\
h=5 & \textbf{XGBoost} & 7.61 & 5.43 & 3.77 & 0.790 & LightGBM & +0.05 \\
h=6 & \textbf{LightGBM} & 8.01 & 5.72 & 3.95 & 0.768 & XGBoost & +0.09 \\
h=7 & \textbf{RandomForest} & 8.18 & 5.75 & 3.95 & 0.759 & LightGBM & +0.14 \\
\midrule
\textbf{Average} & - & \textbf{7.24} & \textbf{5.08} & \textbf{3.53} & \textbf{0.808} & - & - \\
\bottomrule
\end{tabular}
\end{table*}

Several patterns emerge. LightGBM dominates short to medium range forecasting, winning 4 of 7 horizons including the critical next day prediction. XGBoost excels at mid-range (h=2 and h=5), while RandomForest surprisingly wins the longest horizon (h=7). No single algorithm proves optimal everywhere, strongly validating our competition based approach. Tight margins between winners and runners up ($\Delta$ RMSE < 0.25 GWh) indicate all three methods remain competitive, though the small performance differences matter for operational grid management.

Per Lewis benchmarks~\cite{lewis1982}, our h=1 performance at 2.45\% MAPE qualifies as "Excellent" (below 3\%). Horizons h=2 through h=7 achieve "Good" tier (3-5\% range), with the system averaging 3.53\% overall approaching excellent classification. The h=1 model's $R^{2}$ = 0.891 means we explain 89.1\% of consumption variance, with the remaining 11\% likely representing genuinely unpredictable factors: extreme weather events, unexpected industrial shutdowns, measurement noise, and inherent randomness in human behavior.

\subsection{Baseline Comparisons}

Table~\ref{tab:baselines} positions our approach against standard forecasting methods for next day predictions.

\begin{table}[H]
\caption{Baseline Comparisons (Horizon h=1)}
\label{tab:baselines}
\centering
\begin{tabular}{lcc}
\toprule
Method & MAPE (\%) & $R^2$ \\
\midrule
Naive (Persistence) & 8.7 & 0.421 \\
Seasonal Naive (week lag) & 6.2 & 0.672 \\
Moving Average (7-day) & 5.1 & 0.758 \\
Linear Regression & 4.8 & 0.782 \\
\textbf{Our LightGBM} & \textbf{2.45} & \textbf{0.891} \\
\bottomrule
\end{tabular}
\end{table}

Our approach achieves 52\% error reduction versus the 7-day moving average baseline (5.1\% $\rightarrow$ 2.45\%). Simple persistence and seasonal naive methods perform unacceptably for grid operations with MAPE above 6\%. Even linear regression barely meets the 5\% industry threshold. Our ensemble method's performance gap demonstrates the value of sophisticated feature engineering and modern algorithms for this problem.

\subsection{Feature Importance Analysis}

SHAP values for horizon h=1 reveal which features drive predictions:

\begin{enumerate}
    \item consumption\_lag\_1:  Yesterday's consumption
    \item consumption\_lag\_2:  Two days ago
    \item rolling\_mean\_7 : Weekly momentum
    \item consumption\_lag\_7:  Same weekday last week
    \item rolling\_mean\_30: Monthly trend
    \item temperature\_mean :  Primary weather driver
    \item rolling\_std\_7: Weekly volatility
    \item trend\_7days: Directional change
    \item temp\_x\_humidity : Compound weather effect
    \item is\_weekend :  Business activity marker
\end{enumerate}

This ranking confirms the fundamentally auto regressive nature of energy consumption: lag features contribute 40\% of total explanatory power. Temperature emerges as the strongest weather variable, consistent with its -0.39 correlation observed in exploratory analysis. Our weather interaction features (temp × humidity) capture compound effects worth 2.8 SHAP points. Holiday features, while showing high impact on specific days, contribute only 1.6 points to overall importance due to their infrequent occurrence.

\subsection{Error Pattern Analysis}

Performance varies across different temporal contexts. Seasonal analysis shows winter MAPE at 2.8\% (higher variability from heating patterns), spring achieving best performance at 2.1\% (stable weather), summer at 2.3\% (low baseline consumption), and fall at 2.5\% (moderate conditions).

Day of week patterns reveal Monday through Thursday as most predictable (2.2\% MAPE), Friday slightly worse (2.4\%), Saturday more challenging (2.8\%), and Sunday showing highest variability (3.1\%) likely due to unpredictable leisure activities.

Holiday performance remains acceptable despite challenges. MAPE reaches 4.2\% on holidays versus 2.3\% on normal days holidays cause 18\% consumption drops that challenge any forecasting system. However, our Portuguese specific holiday features reduced error from 5.8\% to 4.2\% (28\% improvement), keeping performance in the "Good" tier.

Residual analysis via Shapiro-Wilk test (W=0.9847, p$\approx$0.031) indicates approximately normal distribution with mean error -0.08 GWh (slight under prediction bias), skewness -0.12 (nearly symmetric), and kurtosis 0.31 (light tails). These statistics suggest well behaved prediction errors without systematic biases requiring correction.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Production Deployment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{REST API Architecture}

Our system exposes forecasts through a RESTful API built with FastAPI 0.115.0, served via Uvicorn 0.32.0 ASGI server on port 8000. Table~\ref{tab:api_endpoints} summarizes available endpoints and typical response times measured under normal load.

\begin{table}[H]
\caption{REST API Endpoints and Performance}
\label{tab:api_endpoints}
\centering
\begin{tabular}{lll}
\toprule
Endpoint & Description & Latency \\
\midrule
\texttt{GET /health} & System health check & 5ms \\
\texttt{GET /model/info} & Model metadata & 12ms \\
\texttt{POST /energy/predict-next} & Next-day forecast & 180ms \\
\texttt{POST /energy/forecast/\{days\}} & Multi-day (1-7) forecast & 195ms \\
\texttt{GET /weather/forecast/\{days\}} & Weather data retrieval & 250ms \\
\bottomrule
\end{tabular}
\end{table}

We implemented TTL based caching with 5 minute expiration using Python's \texttt{functools.lru\_cache} decorator. This reduces average endpoint latency by 82\% for repeated requests since weather forecasts and model predictions remain valid for several minutes. The caching strategy balances freshness with performance, automatically invalidating stale data while maximizing throughput for production workloads.

\subsection{Interactive Dashboard}

A Streamlit 1.28 web application provides user friendly access to forecasts and analytics on port 8501. The dashboard organizes functionality across four pages.

The \textbf{Home} page displays the 7-day forecast table with predicted consumption values, overlays forecasts on historical consumption charts, and shows confidence intervals computed from model uncertainty estimates. The \textbf{Weather} page presents current meteorological conditions for Central Portugal alongside 7-day forecasts, visualizing temperature, precipitation, wind, and solar radiation through intuitive cards and icons. The \textbf{EDA} page offers interactive exploratory analysis with temporal pattern visualizations, outlier detection plots, correlation heatmaps, and statistical summaries. The \textbf{Performance} page shows model evaluation metrics per horizon (RMSE, MAE, MAPE, $R^{2}$), error distribution histograms, residual analysis plots, and feature importance rankings.
 
Figure~\ref{fig:dashboard} shows key dashboard interfaces.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/home.png}
        \caption{Home: 7-day forecast with historical context}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/weather.png}
        \caption{Weather: current conditions and forecasts}
    \end{subfigure}
    \caption{Production dashboard interface providing real-time forecast access, weather data, and system analytics}
    \label{fig:dashboard}
\end{figure}

Figure~\ref{fig:dashboard_exploratory} illustrates the exploratory analysis capabilities.

\begin{figure}[H]
    \centering
    \begin{subfigure}{0.3\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/history.png}
        \caption{15-year historical trends}
    \end{subfigure}
    \hfill 
    \begin{subfigure}{0.3\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/outlier.png}
        \caption{Outlier detection analysis}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.3\textwidth}
        \centering
        \includegraphics[width=\linewidth]{../images/week.png}
        \caption{Temporal pattern decomposition}
    \end{subfigure}
    \caption{EDA dashboard enabling interactive investigation of consumption patterns, outliers, and temporal cycles.}
    \label{fig:dashboard_exploratory}
\end{figure}

The dashboard auto refreshes every 5 minutes to display latest forecasts while prominently showing the forecast generation timestamp. Users can interactively explore historical data, zoom into specific periods. The responsive design works across desktop and tablet devices, though mobile phone usage remains suboptimal given the data dense visualizations.

Our technology stack combines Python 3.12 (backend), FastAPI and Uvicorn (API layer), Streamlit 1.28 (frontend), LightGBM 4.1, XGBoost 2.0, and scikit-learn 1.3 (machine learning), with pandas 2.1 and numpy 1.25 handling data manipulation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This work demonstrates how carefully engineered domain specific features combined with modern ensemble methods can achieve state of the art energy forecasting performance while maintaining operational deployability. Our system balances three often competing requirements: prediction accuracy, model interpretability, and production ready reliability.

\subsection{Key Achievements}

We achieved next day forecasting at 2.45\% MAPE qualifying as "Excellent" per Lewis benchmarks~\cite{lewis1982} and positioning this work in the top tier of published energy forecasting research. The system wide average of 3.53\% MAPE across all seven horizons maintains "Good" classification (3-5\% range). Our best model explains 89.1\% of consumption variance ($R^{2}$=0.891), with the remaining 11\% likely representing genuinely unpredictable factors. Compared to the 7-day moving average baseline, we achieved 52\% error reduction (5.1\% $\rightarrow$ 2.45\%). Performance stayed consistent across 5-fold time series cross-validation, demonstrating robustness across different temporal periods. The complete system runs daily in production with REST API, interactive dashboard, and automated pipeline execution.

Our methodological contributions include several novel approaches. Rather than selecting a single algorithm, we let each forecast horizon independently compete RandomForest, LightGBM, and XGBoost. Results validated this strategy: LightGBM excels at short to medium range (4/7 horizons), XGBoost at mid-range (2/7), and RandomForest at long-range (1/7). No single algorithm dominates all horizons.

Portuguese specific calendar features proved particularly valuable. Implementing 13 national holidays plus bridge day detection those days between holidays and weekends where many Portuguese take time off—reduced holiday period error by 28\% (5.8\% $\rightarrow$ 4.2\% MAPE). This demonstrates how country specific domain knowledge outperforms generic temporal features.

Weather interaction features capture compound effects where, for example, high humidity amplifies cold perception beyond temperature alone. These interactions (temp×humidity, temp×wind, temp×rain) account for non linear synergistic relationships and contribute 5\% of total model explanatory power.

SHAP guided feature selection provided principled, interpretable dimensionality reduction from 55 candidates to 30 selected features: lags (40\%), rolling statistics (30\%), weather (18\%), temporal (7\%), interactions (5\%). Every feature demonstrates clear predictive value.

Direct multi horizon forecasting with independent models per horizon prevents error propagation inherent in recursive approaches. This strategy, adopted by 80\% of GEFCom2014 winners~\cite{hong2016}, proved essential for our multi day forecasting system.

Rigorous validation through 5-fold expanding window time series cross-validation plus strict temporal train/test splits (80/20) ensures no data leakage while providing realistic performance estimates for unseen future data.

Table~\ref{tab:baselines} positions our work relative to published studies.

Superior performance stems from four factors: extensive 15-year dataset versus typical 2-4 years in literature, modern gradient boosting algorithms (LightGBM 2017) versus older methods, comprehensive domain specific features including Portuguese holidays and weather interactions, and systematic per horizon algorithm selection rather than one size fits all approaches.

\subsection{Current Limitations}

Several constraints affect the system's scope and applicability. Daily forecasting only no intraday or hourly predictions limits applicability for real-time grid operations requiring sub hourly forecasts. National aggregate forecasting provides no regional or district level breakdowns, preventing localized grid management and distribution planning. Single source dependency on the REN API creates a potential failure point; downtime or data quality issues directly impact forecast generation with no fallback data sources currently implemented.

The system cannot predict unprecedented "black swan" events: pandemics like COVID-19, major grid failures, or extreme weather outside historical distributions. Training on normal operating conditions only means the model lacks experience with truly exceptional scenarios. Weekly retraining may prove insufficient for rapid structural changes in consumption patterns such as sudden industrial closures or policy changes affecting demand.

Model interpretability remains challenging despite SHAP values. While feature importance rankings help, the ensemble's complex non linear transformations resist complete mechanistic understanding that domain experts sometimes require for full confidence in operational decisions.

Each algorithm brings specific trade offs. LightGBM provides fastest training and prediction (20× faster than RandomForest) with memory efficient gradient based sampling, but proves highly sensitive to the num\_leaves hyperparameter where poor tuning causes overfitting or underfitting. XGBoost offers strong L2 regularization preventing overfitting plus robust handling of missing values and excellent stability, yet runs 2-3× slower than LightGBM while requiring more memory for equivalent tree depths. RandomForest shows most robustness to outliers and noisy features with best performance at long horizons (h=7) and minimal hyperparameter tuning requirements, but carries highest memory footprint (storing all trees), slowest prediction latency, and risks overfitting on small datasets.

\subsection{Future Directions}

Short-term extensions (1-3 months) require minimal architectural changes. Hourly forecasting would extend temporal resolution supporting intraday market operations and real-time grid balancing. Probabilistic forecasting via quantile regression could generate prediction intervals (5th-95th percentiles) rather than point forecasts, enabling risk aware decision making. Concept drift detection using statistical tests (Page-Hinkley, ADWIN) would automatically trigger model retraining when distribution shifts exceed thresholds. Comprehensive automated testing covering 80\% of the codebase (unit tests, integration tests, API contract tests) would ensure production reliability.

Medium-term research (3-6 months) involves more substantial advances. Regional forecasting could develop district level models for Portugal's 18 mainland districts plus 2 autonomous regions, enabling localized grid management. Deep learning benchmarking against Temporal Fusion Transformers~\cite{lim2021} and N-BEATS~\cite{oreshkin2019} would quantify performance complexity trade offs. Bayesian hyperparameter optimization via Optuna~\cite{akiba2019} might improve MAPE by an additional 5-10\%. Real-time inference optimization targeting <100ms end-to-end latency would enable integration with time critical systems.

Long-term vision (6-12 months) includes ambitious extensions. Multi country expansion to Spain and France could investigate transfer learning, leveraging Portugal's model for data scarce countries. Renewable generation forecasting would extend beyond consumption to predict wind, solar, and hydro generation, enabling holistic grid management. Electricity price prediction integrating consumption forecasts with market clearing mechanisms could support trading strategies. Causal inference frameworks (Granger causality, structural equation modeling) would identify genuine cause effect relationships beyond correlations. Transfer learning research might show whether models pre trained on Portugal generalize to similar climates and economies like Greece or Southern Italy.

\subsection{Broader Impact}

This work contributes across economic, environmental, and scientific dimensions. Economically, improved day ahead market bidding reduces imbalance penalties. For Portugal's 137 GWh average daily consumption, even 1\% accuracy improvement (1.37 GWh) saves approximately EUR 50,000 daily at typical imbalance prices (EUR 35/MWh). Better demand forecasts enable optimal power plant scheduling, reducing startup/shutdown cycles and lowering operational expenses by 2-3\% industry wide. Enhanced forecast accuracy allows higher renewable penetration by reducing expensive spinning reserves needed to cover forecast errors.

Environmentally, optimized generation scheduling prioritizes low carbon sources (hydro, wind, solar) over fossil fuels when feasible, potentially reducing Portugal's grid CO$_2$ emissions by 1-2\% annually. Accurate demand forecasts let grid operators accept more variable renewable generation confidently without compromising stability, increasing utilization rates by reducing curtailment. Better load forecasting reduces transmission and distribution losses through optimal power flow management, decreasing overall generation requirements along with associated costs and emissions.

Scientifically, this work empirically demonstrates that modern gradient boosting methods outperform deep neural networks for tabular time series with fewer than 10K samples. This contradicts recent literature's bias toward deep learning and validates classical machine learning for practical applications. Our results show domain specific features (Portuguese holidays, bridge days, weather interactions) provide greater accuracy improvements (+28\%) than algorithm selection alone (+3-5\%), validating the principle that feature engineering often matters more than model complexity.

We provide the first comprehensive baseline for Portuguese energy forecasting with 15-year dataset, reproducible methodology, and documented architecture. This enables future researchers to compare against standardized benchmarks rather than inconsistent proprietary systems. By documenting not just models but complete data pipelines, API architecture, monitoring strategies, and retraining schedules, we address engineering considerations often omitted from academic publications yet critical for real world impact.

\subsection{Final Remarks}

Combining modern machine learning algorithms with thoughtful feature engineering and rigorous validation produces forecasting systems that are simultaneously accurate, interpretable, and deployable. Our 2.45\% MAPE for next day forecasting represents 52\% improvement over baseline methods, positioning this system among top tier published energy forecasting research.

Perhaps more importantly, the methodology stays practical and reproducible. By documenting not only the models but also complete data pipeline, API architecture, and deployment infrastructure, this work provides a template for operational energy forecasting systems rather than just academic benchmarks. The system runs daily in production, generating forecasts that could inform real grid management decisions if integrated with operational planning systems.

Future extensions to hourly forecasting, regional granularity, and multi country applicability will further enhance utility. However, even in its current form, this work validates that careful application of established machine learning principles feature engineering, ensemble methods, rigorous validation delivers state of the art performance for critical infrastructure forecasting problems.

\section*{Acknowledgments}
Claude (Anthropic, 2025) assisted with occasional coding issues during development. All research design, data preparation, model implementation, analysis, and conclusions were independently carried out by the author.

\printbibliography

\end{document}